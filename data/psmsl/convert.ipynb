{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is a list of packages that are used in this notebook\n",
    "# these come with python\n",
    "import io\n",
    "import zipfile\n",
    "import functools\n",
    "import bisect\n",
    "import datetime\n",
    "import pathlib\n",
    "import uuid\n",
    "import json\n",
    "\n",
    "# you can install these packages using pip or anaconda\n",
    "# (requests numpy pandas bokeh pyproj statsmodels)\n",
    "\n",
    "# for downloading\n",
    "import requests\n",
    "import netCDF4\n",
    "\n",
    "# computation libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas\n",
    "import simplejson\n",
    "import pandas as pd\n",
    "\n",
    "# coordinate systems\n",
    "import pyproj \n",
    "import shapely.geometry\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tide gauges\n",
    "This notebook converts data from PSMSL and makes it available @ Google Cloud Storage for the sea-level rise viewer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "psmsl_urls = {\n",
    "    'met_monthly': 'http://www.psmsl.org/data/obtaining/met.monthly.data/met_monthly.zip',\n",
    "    'rlr_monthly': 'http://www.psmsl.org/data/obtaining/rlr.monthly.data/rlr_monthly.zip',\n",
    "    'rlr_annual': 'http://www.psmsl.org/data/obtaining/rlr.annual.data/rlr_annual.zip'\n",
    "}\n",
    "psmsl_files = {\n",
    "    'met_monthly': pathlib.Path('~/src/sealevel/data/psmsl/met_monthly.zip').expanduser(),\n",
    "    'rlr_monthly': pathlib.Path('~/src/sealevel/data/psmsl/rlr_monthly.zip').expanduser(),\n",
    "    'rlr_annual': pathlib.Path('~/src/sealevel/data/psmsl/rlr_annual.zip').expanduser()   \n",
    "}\n",
    "default_dataset_name = 'rlr_annual'\n",
    "data_dir = pathlib.Path('~/src/sealevel/data/psmsl/gcs').expanduser()\n",
    "quantity = \"sea_surface_height\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert to DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open the zipfile\n",
    "zipfiles = {}\n",
    "\n",
    "# store reference to zip files, just keep them open\n",
    "for dataset_name in psmsl_files:\n",
    "    stream = open(psmsl_files[dataset_name], 'rb')\n",
    "    zf = zipfile.ZipFile(stream)\n",
    "    zipfiles[dataset_name] = zf\n",
    "\n",
    "# this list contains a table of \n",
    "# station ID, latitude, longitude, station name, coastline code, station code, and quality flag\n",
    "csvtext = zipfiles[dataset_name].read('{}/filelist.txt'.format(dataset_name))\n",
    "# read all the data\n",
    "stations = pd.read_csv(\n",
    "    io.BytesIO(csvtext), \n",
    "    sep=';',\n",
    "    names=('id', 'lat', 'lon', 'name', 'coastline_code', 'station_code', 'quality'),\n",
    "    converters={\n",
    "        'name': str.strip,\n",
    "        'quality': str.strip\n",
    "    }\n",
    ")\n",
    "stations = stations.set_index('id')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'met_monthly': PosixPath('/Users/baart_f/src/sealevel/data/psmsl/met_monthly.zip'),\n",
       " 'rlr_monthly': PosixPath('/Users/baart_f/src/sealevel/data/psmsl/rlr_monthly.zip'),\n",
       " 'rlr_annual': PosixPath('/Users/baart_f/src/sealevel/data/psmsl/rlr_annual.zip')}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "psmsl_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all relevant urls\n",
    "names = {\n",
    "    'datum': '{dataset_name}/RLR_info/{id}.txt',\n",
    "    'diagram': '{dataset_name}/RLR_info/{id}.png',\n",
    "    'diagram_url': 'http://www.psmsl.org/data/obtaining/rlr.diagrams/{id}.php',\n",
    "    'url': 'http://www.psmsl.org/data/obtaining/stations/{id}.php',\n",
    "    'rlr_monthly': '{dataset_name}/data/{id}.rlrdata',\n",
    "    'rlr_annual': '{dataset_name}/data/{id}.rlrdata',\n",
    "    'met_monthly': '{dataset_name}/data/{id}.metdata',\n",
    "    'doc': '{dataset_name}/docu/{id}.txt',\n",
    "    'contact': '{dataset_name}/docu/{id}_auth.txt'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>name</th>\n",
       "      <th>coastline_code</th>\n",
       "      <th>station_code</th>\n",
       "      <th>quality</th>\n",
       "      <th>url</th>\n",
       "      <th>met_monthly_url</th>\n",
       "      <th>rlr_monthly_url</th>\n",
       "      <th>rlr_annual_url</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>48.382850</td>\n",
       "      <td>-4.494838</td>\n",
       "      <td>BREST</td>\n",
       "      <td>190</td>\n",
       "      <td>91</td>\n",
       "      <td>N</td>\n",
       "      <td>http://www.psmsl.org/data/obtaining/stations/1...</td>\n",
       "      <td>68cde77a-e39f-3234-bc03-6c1823ff5b3f.json</td>\n",
       "      <td>225d66c2-4e14-38ad-ac37-d1c293eb55f4.json</td>\n",
       "      <td>44ee6bf2-aa96-3176-a666-538618f9a8c1.json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>53.916667</td>\n",
       "      <td>14.233333</td>\n",
       "      <td>SWINOUJSCIE</td>\n",
       "      <td>110</td>\n",
       "      <td>92</td>\n",
       "      <td>N</td>\n",
       "      <td>http://www.psmsl.org/data/obtaining/stations/2...</td>\n",
       "      <td>aa6b9e00-1026-3ba1-b175-d8b564c19da2.json</td>\n",
       "      <td>0a8386ac-9c5c-35ae-a02e-957f4805ad93.json</td>\n",
       "      <td>b68173a3-841d-32ee-97c7-c391b2ff8c67.json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>51.445639</td>\n",
       "      <td>0.743444</td>\n",
       "      <td>SHEERNESS</td>\n",
       "      <td>170</td>\n",
       "      <td>101</td>\n",
       "      <td>N</td>\n",
       "      <td>http://www.psmsl.org/data/obtaining/stations/3...</td>\n",
       "      <td>2ff0fcda-06a3-3b5e-92c5-f10a3960ef21.json</td>\n",
       "      <td>c67b3c75-3b30-33ad-adb2-62e37df65017.json</td>\n",
       "      <td>12974b4a-c97e-3037-b177-ace03f4098e2.json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>53.313944</td>\n",
       "      <td>-4.620444</td>\n",
       "      <td>HOLYHEAD</td>\n",
       "      <td>170</td>\n",
       "      <td>191</td>\n",
       "      <td>Y</td>\n",
       "      <td>http://www.psmsl.org/data/obtaining/stations/5...</td>\n",
       "      <td>60a74295-9514-3c91-ba09-2d0dae722775.json</td>\n",
       "      <td>35c694f2-9132-38b7-81c6-4c227ada2298.json</td>\n",
       "      <td>53db2d23-26b2-3145-b492-9c6f5ac7880e.json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>53.866667</td>\n",
       "      <td>8.716667</td>\n",
       "      <td>CUXHAVEN 2</td>\n",
       "      <td>140</td>\n",
       "      <td>12</td>\n",
       "      <td>N</td>\n",
       "      <td>http://www.psmsl.org/data/obtaining/stations/7...</td>\n",
       "      <td>fbc469e8-8396-3dbb-96c2-ef3da7f7c208.json</td>\n",
       "      <td>bf66ea18-18a8-3ae7-bf8c-f09ce4a24a1d.json</td>\n",
       "      <td>f4912296-02d6-3200-b334-0e35f5041d69.json</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          lat        lon         name  coastline_code  station_code quality  \\\n",
       "id                                                                            \n",
       "1   48.382850  -4.494838        BREST             190            91       N   \n",
       "2   53.916667  14.233333  SWINOUJSCIE             110            92       N   \n",
       "3   51.445639   0.743444    SHEERNESS             170           101       N   \n",
       "5   53.313944  -4.620444     HOLYHEAD             170           191       Y   \n",
       "7   53.866667   8.716667   CUXHAVEN 2             140            12       N   \n",
       "\n",
       "                                                  url  \\\n",
       "id                                                      \n",
       "1   http://www.psmsl.org/data/obtaining/stations/1...   \n",
       "2   http://www.psmsl.org/data/obtaining/stations/2...   \n",
       "3   http://www.psmsl.org/data/obtaining/stations/3...   \n",
       "5   http://www.psmsl.org/data/obtaining/stations/5...   \n",
       "7   http://www.psmsl.org/data/obtaining/stations/7...   \n",
       "\n",
       "                              met_monthly_url  \\\n",
       "id                                              \n",
       "1   68cde77a-e39f-3234-bc03-6c1823ff5b3f.json   \n",
       "2   aa6b9e00-1026-3ba1-b175-d8b564c19da2.json   \n",
       "3   2ff0fcda-06a3-3b5e-92c5-f10a3960ef21.json   \n",
       "5   60a74295-9514-3c91-ba09-2d0dae722775.json   \n",
       "7   fbc469e8-8396-3dbb-96c2-ef3da7f7c208.json   \n",
       "\n",
       "                              rlr_monthly_url  \\\n",
       "id                                              \n",
       "1   225d66c2-4e14-38ad-ac37-d1c293eb55f4.json   \n",
       "2   0a8386ac-9c5c-35ae-a02e-957f4805ad93.json   \n",
       "3   c67b3c75-3b30-33ad-adb2-62e37df65017.json   \n",
       "5   35c694f2-9132-38b7-81c6-4c227ada2298.json   \n",
       "7   bf66ea18-18a8-3ae7-bf8c-f09ce4a24a1d.json   \n",
       "\n",
       "                               rlr_annual_url  \n",
       "id                                             \n",
       "1   44ee6bf2-aa96-3176-a666-538618f9a8c1.json  \n",
       "2   b68173a3-841d-32ee-97c7-c391b2ff8c67.json  \n",
       "3   12974b4a-c97e-3037-b177-ace03f4098e2.json  \n",
       "5   53db2d23-26b2-3145-b492-9c6f5ac7880e.json  \n",
       "7   f4912296-02d6-3200-b334-0e35f5041d69.json  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add urls to the dataset\n",
    "def get_url(station):\n",
    "    \"\"\"return the url of the station information (diagram and datum)\"\"\"\n",
    "    url = names['url'].format(id=station.name)\n",
    "    return url\n",
    "\n",
    "# compute the url for each station\n",
    "stations['url'] = stations.apply(get_url, axis=1)\n",
    "\n",
    "# create new columns\n",
    "for dataset_name in psmsl_urls:\n",
    "    stations[dataset_name + '_url'] = None\n",
    "\n",
    "for i, station in stations.iterrows():\n",
    "    for dataset_name in psmsl_urls:\n",
    "        uuid_ = str(uuid.uuid3(uuid.NAMESPACE_OID, str(station.name) + \"_\" + dataset_name + '_' + quantity))\n",
    "        url = uuid_ + '.json'\n",
    "        stations.loc[i, dataset_name + '_url'] = url\n",
    "stations.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to geodataframe\n",
    "stations['coordinate'] = list(zip(stations.lon, stations.lat))\n",
    "stations['geometry'] = stations['coordinate'].apply(shapely.geometry.Point)\n",
    "stations = geopandas.GeoDataFrame(stations, geometry='geometry')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GeoJSON\n",
    "We transform the database to a geoson file type, to facilitate the reading of the data on a webserver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns=['lat', 'lon', 'name', 'coastline_code', 'station_code', 'quality', 'coordinate', 'met_monthly_url', 'rlr_monthly_url', 'rlr_annual_url', 'geometry']\n",
    "text=stations[columns].to_json()\n",
    "\n",
    "\n",
    "path_output = data_dir / 'locations.geojson'\n",
    "\n",
    "with path_output.open('w') as f:\n",
    "    f.write(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def station2location(station):\n",
    "    result = {\n",
    "        \"uuid\": str(uuid.uuid3(uuid.NAMESPACE_OID, str(station.name))),\n",
    "        \"url\": station.url,\n",
    "        \"code\": station.name,\n",
    "        \"name\": station['name'],\n",
    "        \"geometry\": station.geometry.__geo_interface__,\n",
    "        \"node\": {\n",
    "            \"uuid\": str(uuid.uuid3(uuid.NAMESPACE_URL, \"https://s3-eu-west-1.amazonaws.com/deltares-opendata\")),\n",
    "            \"name\": \"Deltares\",\n",
    "            \"description\": \"PSMSL data location hosted by Deltares\",\n",
    "            \"baseUrl\": \"https://s3-eu-west-1.amazonaws.com/deltares-opendata\"\n",
    "        }\n",
    "    }\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use response to frame that we use the data from the web after a query. We put the data in a dictionary to fit with the webviewer\n",
    "results = stations.apply(station2location, axis=1)\n",
    "locations_response = {\n",
    "    \"results\": list(results),\n",
    "    \"count\": len(stations.index),\n",
    "    \"maxPageSize\": None,\n",
    "    \"previous\": None,\n",
    "    \"next\": None\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NumpyEncoder(json.JSONEncoder):\n",
    "    \"\"\" Special json encoder for numpy types \"\"\"\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, (np.int_, np.intc, np.intp, np.int8,\n",
    "            np.int16, np.int32, np.int64, np.uint8,\n",
    "            np.uint16, np.uint32, np.uint64)):\n",
    "            return int(obj)\n",
    "        elif isinstance(obj, (np.float_, np.float16, np.float32, \n",
    "            np.float64)):\n",
    "            return float(obj)\n",
    "        elif isinstance(obj,(np.ndarray,)): #### This is the fix\n",
    "            return obj.tolist()\n",
    "        return json.JSONEncoder.default(self, obj)\n",
    "    \n",
    "    \n",
    "with (data_dir / 'locations.json').open('w') as f:\n",
    "    json.dump(locations_response, f, cls=NumpyEncoder )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use nans for missing, a bit more performant than masked arrays\n",
    "def missing2nan(value, missing=-99999):\n",
    "    \"\"\"convert the value to nan if the float of value equals the missing value\"\"\"\n",
    "    value = float(value)\n",
    "    if value == missing:\n",
    "        return np.nan\n",
    "    return value\n",
    "\n",
    "def year2date(year_fraction, dtype='datetime64[s]'):\n",
    "    \"\"\"convert a fraction of a year + fraction of a year to a date, for example 1993.12 -> 1993-02-01.\n",
    "    The dtype should be a valid numpy datetime unit, such as datetime64[s]\"\"\"\n",
    "    startpoints = np.linspace(0, 1, num=12, endpoint=False)\n",
    "    remainder = np.mod(year_fraction, 1)\n",
    "    year = np.floor_divide(year_fraction, 1).astype('int')\n",
    "    month = np.searchsorted(startpoints, remainder)\n",
    "    if (month == 0).all():\n",
    "        # if month is set to 0 (for annual data), set to january\n",
    "        month = np.ones_like(month)\n",
    "    dates = [\n",
    "        datetime.datetime(year_i, month_i, 1) \n",
    "        for year_i, month_i \n",
    "        in zip(year, month)\n",
    "    ]\n",
    "    datetime64s = np.asarray(dates, dtype=dtype)\n",
    "    return datetime64s\n",
    "\n",
    "def get_data(station, dataset_name):\n",
    "    \"\"\"get data for the station (pandas record) from the dataset (url)\"\"\"\n",
    "    info = dict(\n",
    "        dataset_name=dataset_name,\n",
    "        id=station.name\n",
    "    )\n",
    "    bytes = zipfiles[dataset_name].read(names[dataset_name].format(**info))\n",
    "    df = pd.read_csv(\n",
    "        io.BytesIO(bytes), \n",
    "        sep=';', \n",
    "        names=('year', 'height', 'interpolated', 'flags'),\n",
    "        converters={\n",
    "            \"height\": lambda x: missing2nan(x),\n",
    "            \"interpolated\": str.strip,\n",
    "        }\n",
    "    )\n",
    "    df['station'] = station.name\n",
    "    df['t'] = year2date(df.year)\n",
    "    df = df.set_index('t')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data for all stations\n",
    "for dataset_name in psmsl_urls:\n",
    "    f = functools.partial(get_data, dataset_name=dataset_name)\n",
    "    # look up the data for each station\n",
    "    stations[dataset_name] = [f(station) for _, station in stations.iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def station2events(station,dataset_name):\n",
    "    timeseries=station[dataset_name]\n",
    "    df=timeseries[[\"height\"]]    \n",
    "    result = [\n",
    "        {\n",
    "            \"timeStamp\": str(row[0]),\n",
    "            \"value\": row[1].height\n",
    "        }\n",
    "        for row  \n",
    "        in df.iterrows()\n",
    "    ]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def station2timeseries(station,dataset_name, quantity=\"sea_surface_height\"):\n",
    "    result = {        \n",
    "        \"url\": None,\n",
    "        \"uuid\": str(uuid.uuid3(uuid.NAMESPACE_OID, str(station.name) + \"_\" + dataset_name + '_' + quantity)),\n",
    "        \"qualifier\": str(station.name) + \"_\" + dataset_name + '_' + quantity,\n",
    "        \"location\": station2location(station),\n",
    "        \"observationType\": {\n",
    "            \"uuid\": str(uuid.uuid3(uuid.NAMESPACE_OID, quantity)),\n",
    "            \"quantity\": quantity,\n",
    "            \"unit\": \"mm\",\n",
    "            \"parameterCode\": None,\n",
    "            \"compartment\": None,\n",
    "            \"qualifier\": None,\n",
    "            \"extra\": [],\n",
    "        },\n",
    "        \"node\": {\n",
    "            \"uuid\": str(uuid.uuid3(uuid.NAMESPACE_URL, \"https://s3-eu-west-1.amazonaws.com/deltares-opendata\")),\n",
    "            \"name\": \"Deltares\",\n",
    "            \"description\": \"PSMSL data location hosted by Deltares\",\n",
    "            \"baseUrl\": \"https://s3-eu-west-1.amazonaws.com/deltares-opendata\"\n",
    "        },\n",
    "        \"datasource\": {\n",
    "            \"uuid\": str(uuid.uuid3(uuid.NAMESPACE_OID, \"PSMSL\")),\n",
    "            \"name\": 'PSMSL',\n",
    "            \"node\": {\n",
    "                \"uuid\": str(uuid.uuid3(uuid.NAMESPACE_URL, \"https://www.psmsl.org\")),\n",
    "                \"name\": 'PSMSL',\n",
    "                \"description\": 'Permanent Service for Mean Sea Level',\n",
    "                \"baseUrl\": 'http://www.psmsl.org/'\n",
    "                }\n",
    "            },\n",
    "        \"timeseriesType\": {\n",
    "            \"code\": None,\n",
    "            \"name\": \"Measurements\"\n",
    "        },\n",
    "        \"interval\": None,\n",
    "        \"valueType\": \"float\",\n",
    "        \"start\": None,\n",
    "        \"end\": None,\n",
    "        \"events\": station2events(station,dataset_name)\n",
    "    }\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "station = stations.iloc[0]\n",
    "for i, station in stations.iterrows():\n",
    "    for dataset_name in psmsl_urls:\n",
    "        result = station2timeseries(station, dataset_name)\n",
    "        path = (data_dir / result['uuid']).with_suffix('.json')\n",
    "        with path.open('w') as f:\n",
    "            simplejson.dump(result, f, ignore_nan=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
